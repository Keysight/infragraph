{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p>Modern AI systems, comprising diverse scale-up and scale-out interconnect topologies that integrate complex heterogeneous components, connected together via diverse means, face a lack of standardized overall infrastructure description, all which hinders benchmarking, simulation, and emulation.</p> <p>This documentation covers the following:</p>"},{"location":"#background","title":"Background","text":"<p>The background details and justification behind the schema.</p>"},{"location":"#schema","title":"Schema","text":"<p>An overview of the schema and it's repository.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>A simple generic case study demonstrating how to get started.</p>"},{"location":"#extending-the-case-study-with-additional-data","title":"Extending the case study with additional data","text":"<p>This section provides a comprehensive guide on how a user can annotate various parts of infrastructre and add more details like DeviceType, Rank Identifier and so on.</p> <p>It covers the model description with examples for binding physical attributes with the logical infrastructure definition.</p>"},{"location":"#services","title":"Services","text":"<p>The site provides services for <code>validating</code> concrete instances of schemas.</p>"},{"location":"#advanced-examples","title":"Advanced Examples","text":"<p>Advanced examples include such things as:</p> <ul> <li>complex servers</li> <li>composable devices</li> <li>scaleup/scaleout infrastructure.</li> </ul>"},{"location":"#specification-browser","title":"Specification Browser","text":"<p>The API and Models can easily be reviewed using the auto-generated OpenAPI model and redocly html documentation.</p>"},{"location":"#community","title":"Community","text":"<p>Use our community resources to get help with InfraGraph on Github</p>"},{"location":"annotate/","title":"The <code>annotate_graph</code> API","text":""},{"location":"annotate/#overview","title":"Overview","text":"<p>Once the infrastructure or system of systems has been defined by using the <code>set_graph</code> API the base graph can be extended by using the <code>annotate_graph</code> API to add additional data using nodes and edges as endpoints for the data.</p> <p>The main objective of the <code>annotate_graph</code> API is to separate the infrastructure model from specific use-case models by allowing the graph to be extended with any type of data.  This ensures that <code>InfraGraph</code> does not morph into an attempt to define every nuance present in a system of systems.</p> <p>Any annotation efforts can always be proposed as model or service enhancements by submitting issues or pull requests to the InfraGraph repository.</p>"},{"location":"annotate/#additional-data","title":"Additional Data","text":"<p>Some examples of additional data are:   - AI data such as:     - ranks     - communication groups   - Configuration data such as:     - network interface card settings     - device addresses     - device routing tables</p> <p>The following code examples demonstrates how to use the <code>query_graph</code> API in conjunction with the <code>annotate_graph</code> API to extend the graph with additional user specific data.</p>"},{"location":"annotate/#adding-rank-data","title":"Adding <code>rank</code> data","text":"<p>In the Getting Started example, the instances of the <code>Server</code> device were created with the name of <code>host</code> and each instance having a specific number of components with a name of <code>npu</code>.</p> <p>The following code demonstrates adding a <code>rank</code> attribute to every <code>host</code> instance that has a component with the name of <code>npu</code>.</p> Add a rank to each host npu <pre><code>import pytest\nfrom infragraph import *\nfrom infragraph.blueprints.fabrics.closfabric import ClosFabric\nfrom infragraph.infragraph_service import InfraGraphService\n\n\n@pytest.mark.asyncio\nasync def test_rank_annotations():\n    \"\"\"Test adding a rank attribute to every npu node\"\"\"\n    # create the graph\n    service = InfraGraphService()\n    service.set_graph(ClosFabric())\n\n    # query the graph for host npus\n    npu_request = QueryRequest()\n    filter = npu_request.node_filters.add(name=\"npu filter\")\n    filter.choice = QueryNodeFilter.ID_FILTER\n    filter.id_filter.operator = QueryNodeId.REGEX\n    filter.id_filter.value = r\"host\\.\\d+\\.npu\\.\\d+\"\n    npu_response = service.query_graph(npu_request)\n\n    # annotate the graph\n    annotate_request = AnnotateRequest()\n    for idx, match in enumerate(npu_response.node_matches):\n        annotate_request.nodes.add(name=match.id, attribute=\"rank\", value=str(idx))\n    service.annotate_graph(annotate_request)\n\n    # query the graph for rank attributes\n    rank_request = QueryRequest()\n    filter = rank_request.node_filters.add(name=\"rank filter\")\n    filter.choice = QueryNodeFilter.ATTRIBUTE_FILTER\n    filter.attribute_filter.name = \"rank\"\n    filter.attribute_filter.operator = QueryNodeId.REGEX\n    filter.attribute_filter.value = r\"\\d+\"\n    rank_response = service.query_graph(rank_request)\n\n    # validation\n    assert len(npu_response.node_matches) &gt; 0\n    assert len(npu_response.node_matches) == len(annotate_request.nodes)\n    assert len(annotate_request.nodes) == len(rank_response.node_matches)\n\n\nif __name__ == \"__main__\":\n    pytest.main([\"-s\", __file__])\n</code></pre>"},{"location":"annotate/#adding-ipaddress-data","title":"Adding <code>ipaddress</code> data","text":"<p>In the Getting Started example, the instances of the <code>Server</code> device were created with the name of <code>host</code> and each instance having a <code>mgmt</code> nic component.</p> <p>The following code demonstrates adding an <code>ipaddress</code> attribute to the <code>host</code> instance <code>mgmt</code> nic.</p> Add an ipaddress to each host mgmt component <pre><code>import pytest\nimport ipaddress\nfrom infragraph import *\nfrom infragraph.blueprints.fabrics.closfabric import ClosFabric\nfrom infragraph.infragraph_service import InfraGraphService\n\n\n@pytest.mark.asyncio\nasync def test_ipaddress_annotations():\n    \"\"\"Test adding an ipaddress attribute to every server nic node\"\"\"\n    # create the graph\n    service = InfraGraphService()\n    service.set_graph(ClosFabric())\n\n    # query the graph for host nics\n    npu_request = QueryRequest()\n    filter = npu_request.node_filters.add(name=\"mgmt nic filter\")\n    filter.choice = QueryNodeFilter.ATTRIBUTE_FILTER\n    filter.attribute_filter.name = \"type\"\n    filter.attribute_filter.operator = QueryNodeId.EQ\n    filter.attribute_filter.value = \"mgmt-nic\"\n    nic_response = service.query_graph(npu_request)\n    print(nic_response.node_matches)\n\n    # annotate the graph\n    annotate_request = AnnotateRequest()\n    for idx, match in enumerate(nic_response.node_matches):\n        annotate_request.nodes.add(\n            name=match.id,\n            attribute=\"ipaddress\",\n            value=str(ipaddress.ip_address(idx)),\n        )\n    service.annotate_graph(annotate_request)\n\n    # query the graph for ipaddress attributes\n    ipaddress_request = QueryRequest()\n    filter = ipaddress_request.node_filters.add(name=\"ipaddress filter\")\n    filter.choice = QueryNodeFilter.ATTRIBUTE_FILTER\n    filter.attribute_filter.name = \"ipaddress\"\n    filter.attribute_filter.operator = QueryNodeId.REGEX\n    filter.attribute_filter.value = r\".*\"\n    ipaddress_response = service.query_graph(ipaddress_request)\n    print(ipaddress_response.node_matches)\n\n    # validation\n    assert len(nic_response.node_matches) &gt; 0\n    assert len(nic_response.node_matches) == len(annotate_request.nodes)\n    assert len(annotate_request.nodes) == len(ipaddress_response.node_matches)\n\n\nif __name__ == \"__main__\":\n    pytest.main([\"-s\", __file__])\n</code></pre>"},{"location":"background/","title":"Background","text":""},{"location":"background/#the-challenge-in-system-description","title":"The Challenge in System Description","text":"<p>Building and managing AI/HPC systems today feels a bit like untangling a giant ball of yarn.</p> <p>Modern AI systems integrate <code>complex, heterogeneous components like compute, memory, and storage</code>, all connected by diverse scale-up and scale-out interconnect topologies. Think of the <code>intricate networks</code> in a large AI factory \u2013 it's a mix of different technologies and topologies.\"</p> <p>But, a clear, <code>standardized</code> way to describe this overall infrastructure is missing. This isn't just a technical challenge; it creates real problems for everyone involved. It makes it incredibly difficult to benchmark, to simulate 'what-if' scenarios, or even to manage these systems efficiently. The result? <code>Significant operational overhead</code>, often <code>low hardware utilization</code>, and a <code>lot of frustration</code> for those trying to get these powerful systems to perform.\"</p> <p>We believe <code>capturing this diversity, this inherent complexity, in a structured way</code> is the first step to reasoning with it.\"</p>"},{"location":"background/#why-standardize","title":"Why Standardize?","text":"<p>Why go through all this effort? Because we want to move beyond just 'making it work' to truly 'optimizing it.' Our goal is to transform massive AI clusters from monolithic problems into structured, analyzable systems. When you have a <code>standardized description</code>, you can feed that information directly into your tools \u2013 your simulators, your emulators, even your deployment systems.</p> <p>This means better predictions about how your AI workloads will perform before you even run them. And it opens the door for something really powerful when doing <code>vertical co-design.</code> It's about making sure your hardware and software are talking to each other, working together seamlessly, from the lowest-level chip to the highest-level application. This ensures accurate performance prediction and validates AI workloads pre-deployment.</p> <p>This isn't just about efficiency; it's about building performant, reliable, and cost-effective AI infrastructure that can keep up with the demands of tomorrow and experimenting with what-if scenarios.  Let's look at a concrete example.</p>"},{"location":"background/#from-schema-to-simulationemulation","title":"From Schema to Simulation/Emulation","text":"<p>So, here's how we put it all together. The challenge is that these complex AI systems are incredibly difficult to model accurately. Say you have a particular infrastructure benchmark like looking at how collective libraries will perform given different design choices, A vs. B.</p> <p>Our solution involves combining two key pieces: our <code>InfraGraph schema</code>, which precisely defines the cluster's topology, and the MLCommons Chakra workload traces, which capture the actual behavior of AI applications.</p> <p>Together, these standardized inputs feed directly into powerful simulators like AstraSim. This isn't just theoretical; it's a working proof point. It allows us to run detailed 'what-if' analyses, explore different design choices of how a cluster is composed together, and truly understand performance trade-offs.</p> <p>This capability effectively <code>democratizes</code> the evaluation of complex AI systems, putting powerful analysis tools into more hands.</p> <ul> <li>infrastructure schema + MLCommons Chakra<ul> <li>standardized <code>infrastructure schema</code> defines system of systems</li> <li><code>chakra</code> provides workload traces</li> </ul> </li> <li>topology input for various tools (ASTRA-Sim)</li> <li>enabled <code>what-if</code> analysis, design choices</li> <li>democratizes complex system evaluation</li> <li>an <code>infrastructure schema</code> is a flexible starting point today</li> </ul>"},{"location":"create/","title":"Case Study: Two Tier Clos Fabric","text":"<p>The main steps in designing a network infrastructure are as follows:</p> <ul> <li>Use text and/or diagrams to create an <code>infrastructure description</code></li> <li>Then <code>use the standardized schema to capture the infrastructure description</code> in a machine readable format by doing the following:<ul> <li>Add infrastructure <code>device</code> subgraphs using <code>components</code> and <code>links</code> to create <code>edges</code> between components</li> <li>Add infrastructure <code>instances</code> to define the number of devices in a reusable manner</li> <li>Add infrastructure <code>links</code> to define additional information that exists between device <code>instances</code> in the infrastructure</li> <li>Add infrastructure <code>edges</code> between device <code>instances</code></li> </ul> </li> </ul>"},{"location":"create/#infrastructure-description","title":"Infrastructure Description","text":"<p>The following is a diagrammatic and textual description of a <code>generic two tier clos fabric</code> that will be modeled using the standardized schema.</p> <p></p> <p>It consists of the following devices:</p> <ul> <li>4 generic <code>servers</code> with each server composed of 4 npus and 4 nics with each nic directly connected to one npu via a pcie link.  Also every npu in a server is connected to every other npu by an nvlink switch. In addition the server includes a management nic that is separate from test nics.</li> <li>4 <code>leaf switches</code> composed of one asic and 16 ethernet ports</li> <li>3 <code>spine switches</code> composed of one asic and 16 ethernet ports</li> </ul> <p>The above devices will be interconnected in the following manner:</p> <ul> <li>each <code>leaf</code> switch is connected directly to 1 <code>server</code> and to all <code>spine</code> switches</li> <li>every <code>server</code> is connected to a <code>leaf</code> switch at 100 gpbs</li> <li>every <code>leaf</code> switch is connected to every <code>spine</code> switch at 400 gpbs</li> </ul>"},{"location":"create/#standardized-definitions","title":"Standardized Definitions","text":"<p>A standardized definition of the preceding two tier clos fabric can be created by following these steps:</p> <ul> <li>The device is a subgraph which is composed of two components connected to each other using a link.</li> <li>It acts as a blueprint allowing for a single definition to be reused multiple times for optimal space complexity.</li> </ul>"},{"location":"create/#create-a-server-device","title":"Create a Server Device","text":"<p>Define a server device based on the infrastructure description.</p> Server device definition using OpenApiArt generated classes <pre><code>from infragraph import *\n\n# pyright: reportArgumentType=false\n\n\nclass Server(Device):\n    def __init__(self, npu_factor: int = 1):\n        \"\"\"Adds an InfraGraph device to infrastructure based on the following components:\n        - 1 cpu for every 2 npus\n        - 1 pcie switch for every 1 cpu\n        - X npus = npu_factor * 2\n        - 1 nic for every npu with 2 nics connected to a pcie switch\n        - 1 nvswitch connected to all npus\n        \"\"\"\n        super(Device, self).__init__()\n        self.name = \"server\"\n        self.description = \"A generic server with npu_factor * 4 npu(s)\"\n\n        cpu = self.components.add(\n            name=\"cpu\",\n            description=\"Generic CPU\",\n            count=npu_factor,\n        )\n        cpu.choice = Component.CPU\n        npu = self.components.add(\n            name=\"npu\",\n            description=\"Generic GPU/NPU\",\n            count=npu_factor * 2,\n        )\n        npu.choice = Component.NPU\n        nvlsw = self.components.add(\n            name=\"nvlsw\",\n            description=\"NVLink Switch\",\n            count=1,\n        )\n        nvlsw.choice = Component.SWITCH\n        pciesw = self.components.add(\n            name=\"pciesw\",\n            description=\"PCI Express Switch Gen 4\",\n            count=npu_factor,\n        )\n        pciesw.choice = Component.SWITCH\n        nic = self.components.add(\n            name=\"nic\",\n            description=\"Generic Nic\",\n            count=npu_factor * 2,\n        )\n        nic.choice = Component.NIC\n        mgmt = self.components.add(\n            name=\"mgmt\",\n            description=\"Mgmt Nic\",\n            count=1,\n        )\n        mgmt.custom.type = \"mgmt-nic\"\n\n        cpu_fabric = self.links.add(name=\"fabric\", description=\"CPU Fabric\")\n        nvlink = self.links.add(name=\"nvlink\")\n        pcie = self.links.add(name=\"pcie\")\n\n        edge = self.edges.add(scheme=DeviceEdge.ONE2ONE, link=pcie.name)\n        edge.ep1.component = mgmt.name\n        edge.ep2.component = f\"{cpu.name}[0]\"\n\n        edge = self.edges.add(scheme=DeviceEdge.MANY2MANY, link=cpu_fabric.name)\n        edge.ep1.component = cpu.name\n        edge.ep2.component = cpu.name\n\n        edge = self.edges.add(scheme=DeviceEdge.MANY2MANY, link=nvlink.name)\n        edge.ep1.component = npu.name\n        edge.ep2.component = nvlsw.name\n\n        for idx in range(pciesw.count):\n            edge = self.edges.add(scheme=DeviceEdge.MANY2MANY, link=pcie.name)\n            edge.ep1.component = f\"{cpu.name}[{idx}]\"\n            edge.ep2.component = f\"{pciesw.name}[{idx}]\"\n\n        npu_slices = [f\"{idx}:{idx+2}\" for idx in range(0, npu.count, 2)]\n        for npu_idx, pciesw_idx in zip(npu_slices, range(pciesw.count)):\n            edge = self.edges.add(scheme=DeviceEdge.MANY2MANY, link=pcie.name)\n            edge.ep1.component = f\"{npu.name}[{npu_idx}]\"\n            edge.ep2.component = f\"{pciesw.name}[{pciesw_idx}]\"\n\n        for nic_idx, pciesw_idx in zip(npu_slices, range(pciesw.count)):\n            edge = self.edges.add(scheme=DeviceEdge.MANY2MANY, link=pcie.name)\n            edge.ep1.component = f\"{nic.name}[{nic_idx}]\"\n            edge.ep2.component = f\"{pciesw.name}[{pciesw_idx}]\"\n\n\nif __name__ == \"__main__\":\n    device = Server(npu_factor=2)\n    device.validate()\n    print(device.serialize(encoding=Device.YAML))\n</code></pre> Server device definition as yaml <pre><code>components:\n- choice: cpu\n  count: 1\n  description: Generic CPU\n  name: cpu\n- choice: npu\n  count: 2\n  description: Generic GPU/NPU\n  name: npu\n- choice: switch\n  count: 1\n  description: NVLink Switch\n  name: nvlsw\n- choice: switch\n  count: 1\n  description: PCI Express Switch Gen 4\n  name: pciesw\n- choice: nic\n  count: 2\n  description: Generic Nic\n  name: nic\n- choice: custom\n  count: 1\n  custom:\n    type: mgmt-nic\n  description: Mgmt Nic\n  name: mgmt\ndescription: A generic server with npu_factor * 4 npu(s)\nedges:\n- ep1:\n    component: mgmt\n  ep2:\n    component: cpu[0]\n  link: pcie\n  scheme: one2one\n- ep1:\n    component: cpu\n  ep2:\n    component: cpu\n  link: fabric\n  scheme: many2many\n- ep1:\n    component: npu\n  ep2:\n    component: nvlsw\n  link: nvlink\n  scheme: many2many\n- ep1:\n    component: cpu[0]\n  ep2:\n    component: pciesw[0]\n  link: pcie\n  scheme: many2many\n- ep1:\n    component: npu[0:2]\n  ep2:\n    component: pciesw[0]\n  link: pcie\n  scheme: many2many\n- ep1:\n    component: nic[0:2]\n  ep2:\n    component: pciesw[0]\n  link: pcie\n  scheme: many2many\nlinks:\n- description: CPU Fabric\n  name: fabric\n- name: nvlink\n- name: pcie\nname: server\n</code></pre>"},{"location":"create/#create-a-switch-device","title":"Create a Switch Device","text":"<p>Define a switch device based on the infrastructure description.</p> Switch device definition using OpenApiArt generated classes <pre><code>from infragraph import *\n\n# pyright: reportArgumentType=false\n\n\nclass Switch(Device):\n    def __init__(self, port_count: int = 16):\n        \"\"\"Adds an InfraGraph device to infrastructure based on the following components:\n        - 1 generic asic\n        - nic_count number of ports\n        - integrated circuitry connecting ports to asic\n        \"\"\"\n        super(Device, self).__init__()\n        self.name = \"switch\"\n        self.description = \"A generic switch\"\n\n        asic = self.components.add(\n            name=\"asic\",\n            description=\"Generic ASIC\",\n            count=1,\n        )\n        asic.choice = Component.CPU\n        port = self.components.add(\n            name=\"port\",\n            description=\"Generic port\",\n            count=port_count,\n        )\n        port.choice = Component.PORT\n\n        ic = self.links.add(name=\"ic\", description=\"Generic integrated circuitry\")\n\n        edge = self.edges.add(scheme=DeviceEdge.MANY2MANY, link=ic.name)\n        edge.ep1.component = asic.name\n        edge.ep2.component = port.name\n\n\nif __name__ == \"__main__\":\n    device = Switch()\n    print(device.serialize(encoding=Device.YAML))\n</code></pre> Switch device definition as yaml <pre><code>components:\n- choice: cpu\n  count: 1\n  description: Generic ASIC\n  name: asic\n- choice: port\n  count: 16\n  description: Generic port\n  name: port\ndescription: A generic switch\nedges:\n- ep1:\n    component: asic\n  ep2:\n    component: port\n  link: ic\n  scheme: many2many\nlinks:\n- description: Generic integrated circuitry\n  name: ic\nname: switch\n</code></pre>"},{"location":"create/#create-an-infrastructure-of-instances-of-devices-links-and-edges","title":"Create an Infrastructure of Instances of devices, Links and Edges","text":"<p>Define an infrastructure based on the infrastructure description.</p> Two Tier Clos Fabric Infrastructure using OpenApiArt generated classes <pre><code>from infragraph import *\nfrom infragraph.blueprints.devices.server import Server\nfrom infragraph.blueprints.devices.generic_switch import Switch\nfrom infragraph.infragraph_service import InfraGraphService\n\n\nclass ClosFabric(Infrastructure):\n    \"\"\"Return a 2 tier clos fabric with the following characteristics:\n    - 4 generic servers\n    - each generic server with 2 npus and 2 nics\n    - 4 leaf switches each with 16 ports\n    - 3 spine switch each with 16 ports\n    - connectivity between servers and leaf switches is 100G\n    - connectivity between servers and spine switch is 400G\n    \"\"\"\n\n    def __init__(self):\n        super().__init__(name=\"closfabric\", description=\"2 Tier Clos Fabric\")\n\n        server = Server()\n        switch = Switch()\n        self.devices.append(server).append(switch)\n\n        hosts = self.instances.add(name=\"host\", device=server.name, count=4)\n        leaf_switches = self.instances.add(name=\"leafsw\", device=switch.name, count=4)\n        spine_switches = self.instances.add(name=\"spinesw\", device=switch.name, count=3)\n\n        leaf_link = self.links.add(\n            name=\"leaf-link\",\n            description=\"Link characteristics for connectivity between servers and leaf switches\",\n        )\n        leaf_link.physical.bandwidth.gigabits_per_second = 100\n        spine_link = self.links.add(\n            name=\"spine-link\",\n            description=\"Link characteristics for connectivity between leaf switches and spine switches\",\n        )\n        spine_link.physical.bandwidth.gigabits_per_second = 400\n\n        host_component = InfraGraphService.get_component(server, Component.NIC)\n        switch_component = InfraGraphService.get_component(switch, Component.PORT)\n\n        # link each host to one leaf switch\n        for idx in range(hosts.count):\n            edge = self.edges.add(scheme=InfrastructureEdge.ONE2ONE, link=leaf_link.name)\n            edge.ep1.instance = f\"{hosts.name}[{idx}]\"\n            edge.ep1.component = host_component.name\n            edge.ep2.instance = f\"{leaf_switches.name}[{idx}]\"\n            edge.ep2.component = switch_component.name\n\n        # link every leaf switch to every spine switch\n        print()\n        for leaf_idx in range(leaf_switches.count):\n            for spine_idx in range(spine_switches.count):\n                edge = self.edges.add(scheme=InfrastructureEdge.ONE2ONE, link=spine_link.name)\n                edge.ep1.instance = f\"{leaf_switches.name}[{leaf_idx}]\"\n                edge.ep1.component = f\"{switch_component.name}[{host_component.count + spine_idx}]\"\n                edge.ep2.instance = f\"{spine_switches.name}[{spine_idx}]\"\n                edge.ep2.component = f\"{switch_component.name}[{leaf_idx}]\"\n</code></pre> ClosFabric infrastructure definition as yaml <pre><code>description: 2 Tier Clos Fabric\ndevices:\n- components:\n  - choice: cpu\n    count: 1\n    description: Generic CPU\n    name: cpu\n  - choice: npu\n    count: 2\n    description: Generic GPU/NPU\n    name: npu\n  - choice: switch\n    count: 1\n    description: NVLink Switch\n    name: nvlsw\n  - choice: switch\n    count: 1\n    description: PCI Express Switch Gen 4\n    name: pciesw\n  - choice: nic\n    count: 2\n    description: Generic Nic\n    name: nic\n  - choice: custom\n    count: 1\n    custom:\n      type: mgmt-nic\n    description: Mgmt Nic\n    name: mgmt\n  description: A generic server with npu_factor * 4 npu(s)\n  edges:\n  - ep1:\n      component: mgmt\n    ep2:\n      component: cpu[0]\n    link: pcie\n    scheme: one2one\n  - ep1:\n      component: cpu\n    ep2:\n      component: cpu\n    link: fabric\n    scheme: many2many\n  - ep1:\n      component: npu\n    ep2:\n      component: nvlsw\n    link: nvlink\n    scheme: many2many\n  - ep1:\n      component: cpu[0]\n    ep2:\n      component: pciesw[0]\n    link: pcie\n    scheme: many2many\n  - ep1:\n      component: npu[0:2]\n    ep2:\n      component: pciesw[0]\n    link: pcie\n    scheme: many2many\n  - ep1:\n      component: nic[0:2]\n    ep2:\n      component: pciesw[0]\n    link: pcie\n    scheme: many2many\n  links:\n  - description: CPU Fabric\n    name: fabric\n  - name: nvlink\n  - name: pcie\n  name: server\n- components:\n  - choice: cpu\n    count: 1\n    description: Generic ASIC\n    name: asic\n  - choice: port\n    count: 16\n    description: Generic port\n    name: port\n  description: A generic switch\n  edges:\n  - ep1:\n      component: asic\n    ep2:\n      component: port\n    link: ic\n    scheme: many2many\n  links:\n  - description: Generic integrated circuitry\n    name: ic\n  name: switch\nedges:\n- ep1:\n    component: nic\n    instance: host[0]\n  ep2:\n    component: port\n    instance: leafsw[0]\n  link: leaf-link\n  scheme: one2one\n- ep1:\n    component: nic\n    instance: host[1]\n  ep2:\n    component: port\n    instance: leafsw[1]\n  link: leaf-link\n  scheme: one2one\n- ep1:\n    component: nic\n    instance: host[2]\n  ep2:\n    component: port\n    instance: leafsw[2]\n  link: leaf-link\n  scheme: one2one\n- ep1:\n    component: nic\n    instance: host[3]\n  ep2:\n    component: port\n    instance: leafsw[3]\n  link: leaf-link\n  scheme: one2one\n- ep1:\n    component: port[2]\n    instance: leafsw[0]\n  ep2:\n    component: port[0]\n    instance: spinesw[0]\n  link: spine-link\n  scheme: one2one\n- ep1:\n    component: port[3]\n    instance: leafsw[0]\n  ep2:\n    component: port[0]\n    instance: spinesw[1]\n  link: spine-link\n  scheme: one2one\n- ep1:\n    component: port[4]\n    instance: leafsw[0]\n  ep2:\n    component: port[0]\n    instance: spinesw[2]\n  link: spine-link\n  scheme: one2one\n- ep1:\n    component: port[2]\n    instance: leafsw[1]\n  ep2:\n    component: port[1]\n    instance: spinesw[0]\n  link: spine-link\n  scheme: one2one\n- ep1:\n    component: port[3]\n    instance: leafsw[1]\n  ep2:\n    component: port[1]\n    instance: spinesw[1]\n  link: spine-link\n  scheme: one2one\n- ep1:\n    component: port[4]\n    instance: leafsw[1]\n  ep2:\n    component: port[1]\n    instance: spinesw[2]\n  link: spine-link\n  scheme: one2one\n- ep1:\n    component: port[2]\n    instance: leafsw[2]\n  ep2:\n    component: port[2]\n    instance: spinesw[0]\n  link: spine-link\n  scheme: one2one\n- ep1:\n    component: port[3]\n    instance: leafsw[2]\n  ep2:\n    component: port[2]\n    instance: spinesw[1]\n  link: spine-link\n  scheme: one2one\n- ep1:\n    component: port[4]\n    instance: leafsw[2]\n  ep2:\n    component: port[2]\n    instance: spinesw[2]\n  link: spine-link\n  scheme: one2one\n- ep1:\n    component: port[2]\n    instance: leafsw[3]\n  ep2:\n    component: port[3]\n    instance: spinesw[0]\n  link: spine-link\n  scheme: one2one\n- ep1:\n    component: port[3]\n    instance: leafsw[3]\n  ep2:\n    component: port[3]\n    instance: spinesw[1]\n  link: spine-link\n  scheme: one2one\n- ep1:\n    component: port[4]\n    instance: leafsw[3]\n  ep2:\n    component: port[3]\n    instance: spinesw[2]\n  link: spine-link\n  scheme: one2one\ninstances:\n- count: 4\n  device: server\n  name: host\n- count: 4\n  device: switch\n  name: leafsw\n- count: 3\n  device: switch\n  name: spinesw\nlinks:\n- description: Link characteristics for connectivity between servers and leaf switches\n  name: leaf-link\n  physical:\n    bandwidth:\n      choice: gigabits_per_second\n      gigabits_per_second: 100\n- description: Link characteristics for connectivity between leaf switches and spine\n    switches\n  name: spine-link\n  physical:\n    bandwidth:\n      choice: gigabits_per_second\n      gigabits_per_second: 400\nname: closfabric\n</code></pre>"},{"location":"examples/","title":"Examples","text":"<p>These examples demonstrate <code>describing</code> a variety of devices and infrastructures using text descriptions and diagrams to <code>defining</code> them using a <code>standardized schema</code>.</p>"},{"location":"examples/#dgx-a100-server","title":"DGX-A100 Server","text":"<p>This server diagram acts as an example of how multiple components can be connected to a single component such as multiple gpu components are connected to a single pcie switch.</p> <p>The graph model is able to capture the asymmetric layout of the device.</p>"},{"location":"examples/#description","title":"Description","text":""},{"location":"examples/#standardized-definition","title":"Standardized Definition","text":"DGX device definition using OpenApiArt generated classes <pre><code>from typing import Optional\nfrom infragraph import *\n\n# pyright: reportArgumentType=false\n\n\nclass Dgx(Device):\n    def __init__(self, nic_device: Optional[Device] = None):\n        \"\"\"Adds an InfraGraph device to infrastructure based on the following components:\n        - 2 cpus\n        - 8 npus\n        - 4 pcie switches\n        - 8 nics\n        - 1 nvlink switch\n        \"\"\"\n        super(Device, self).__init__()\n        self.name = \"dgx\"\n        self.description = \"Nvidia DGX System\"\n\n        cpu = self.components.add(\n            name=\"cpu\",\n            description=\"AMD Epyc 7742 CPU\",\n            count=2,\n        )\n        cpu.choice = Component.CPU\n        npu = self.components.add(\n            name=\"npu\",\n            description=\"Nvidia A100 GPU\",\n            count=8,\n        )\n        npu.choice = Component.NPU\n        nvlsw = self.components.add(\n            name=\"nvlsw\",\n            description=\"NVLink Switch\",\n            count=1,\n        )\n        nvlsw.choice = Component.CUSTOM\n        pciesw = self.components.add(\n            name=\"pciesw\",\n            description=\"PCI Express Switch Gen 4\",\n            count=4,\n        )\n        pciesw.choice = Component.CUSTOM\n        if nic_device is None:\n            nic = self.components.add(\n                name=\"nic\",\n                description=\"Generic Nic\",\n                count=8,\n            )\n            nic.choice = Component.NIC\n        else:\n            nic = self.components.add(\n                name=nic_device.name,\n                description=nic_device.description,\n                count=8,\n            )\n            nic.choice = Component.DEVICE\n\n        cpu_fabric = self.links.add(name=\"fabric\", description=\"AMD Infinity Fabric\")\n        pcie = self.links.add(name=\"pcie\")\n        nvlink = self.links.add(name=\"nvlink\")\n\n        edge = self.edges.add(scheme=DeviceEdge.MANY2MANY, link=cpu_fabric.name)\n        edge.ep1.component = cpu.name\n        edge.ep2.component = cpu.name\n\n        edge = self.edges.add(scheme=DeviceEdge.MANY2MANY, link=nvlink.name)\n        edge.ep1.component = npu.name\n        edge.ep2.component = nvlsw.name\n\n        for npu_idx, pciesw_idx in zip([\"0:2\", \"2:4\", \"4:6\", \"6:8\"], range(pciesw.count)):\n            edge = self.edges.add(scheme=DeviceEdge.MANY2MANY, link=pcie.name)\n            edge.ep1.component = f\"{npu.name}[{npu_idx}]\"\n            edge.ep2.component = f\"{pciesw.name}[{pciesw_idx}]\"\n\n        for nic_idx, pciesw_idx in zip([\"0:2\", \"2:4\", \"4:6\", \"6:8\"], range(pciesw.count)):\n            edge = self.edges.add(scheme=DeviceEdge.MANY2MANY, link=pcie.name)\n            edge.ep1.component = f\"{nic.name}[{nic_idx}]\"\n            edge.ep2.component = f\"{pciesw.name}[{pciesw_idx}]\"\n\n\nif __name__ == \"__main__\":\n    device = Dgx()\n    print(device.serialize(encoding=Device.YAML))\n</code></pre> DGX device definition as yaml <pre><code>components:\n- choice: cpu\n  count: 2\n  description: AMD Epyc 7742 CPU\n  name: cpu\n- choice: npu\n  count: 8\n  description: Nvidia A100 GPU\n  name: npu\n- choice: custom\n  count: 1\n  description: NVLink Switch\n  name: nvlsw\n- choice: custom\n  count: 4\n  description: PCI Express Switch Gen 4\n  name: pciesw\n- choice: nic\n  count: 8\n  description: Generic Nic\n  name: nic\ndescription: Nvidia DGX System\nedges:\n- ep1:\n    component: cpu\n  ep2:\n    component: cpu\n  link: fabric\n  scheme: many2many\n- ep1:\n    component: npu\n  ep2:\n    component: nvlsw\n  link: nvlink\n  scheme: many2many\n- ep1:\n    component: npu[0:2]\n  ep2:\n    component: pciesw[0]\n  link: pcie\n  scheme: many2many\n- ep1:\n    component: npu[2:4]\n  ep2:\n    component: pciesw[1]\n  link: pcie\n  scheme: many2many\n- ep1:\n    component: npu[4:6]\n  ep2:\n    component: pciesw[2]\n  link: pcie\n  scheme: many2many\n- ep1:\n    component: npu[6:8]\n  ep2:\n    component: pciesw[3]\n  link: pcie\n  scheme: many2many\n- ep1:\n    component: nic[0:2]\n  ep2:\n    component: pciesw[0]\n  link: pcie\n  scheme: many2many\n- ep1:\n    component: nic[2:4]\n  ep2:\n    component: pciesw[1]\n  link: pcie\n  scheme: many2many\n- ep1:\n    component: nic[4:6]\n  ep2:\n    component: pciesw[2]\n  link: pcie\n  scheme: many2many\n- ep1:\n    component: nic[6:8]\n  ep2:\n    component: pciesw[3]\n  link: pcie\n  scheme: many2many\nlinks:\n- description: AMD Infinity Fabric\n  name: fabric\n- name: pcie\n- name: nvlink\nname: dgx\n</code></pre>"},{"location":"examples/#gh200-mgx","title":"GH200-MGX","text":""},{"location":"examples/#description_1","title":"Description","text":""},{"location":"examples/#npu-component","title":"NPU Component","text":""},{"location":"examples/#device","title":"Device","text":""},{"location":"examples/#standardized-definition_1","title":"Standardized Definition","text":"GH200-MGX device definition using OpenApiArt generated classes <pre><code>TBD...\n</code></pre>"},{"location":"examples/#scaleupscaleout-infrastructure","title":"ScaleUp/ScaleOut Infrastructure","text":""},{"location":"examples/#description_2","title":"Description","text":"<p> https://mips.com/blog/reimagining-ai-infrastructure-the-power-of-converged-back-end-networks/</p> <ul> <li>1024 hosts<ul> <li>1 npu/host</li> <li>10 nics/host</li> </ul> </li> <li>512 scaleup switches<ul> <li>16 ports/switch</li> </ul> </li> <li>2 scaleout switches<ul> <li>1024 ports/switch</li> </ul> </li> <li>64 Racks<ul> <li>16 hosts/rack</li> <li>8 scale up switches/rack</li> </ul> </li> </ul> <p></p>"},{"location":"examples/#standardized-definition_2","title":"Standardized Definition","text":"ScaleUp/ScaleOut infrastructure definition using OpenApiArt generated classes <pre><code>TBD...\n</code></pre>"},{"location":"model/","title":"Model","text":""},{"location":"model/#formal-model-infrastructure-as-a-graph","title":"Formal Model - Infrastructure As A Graph","text":"<p>The formal model specification can be found on GitHub under Infrastructure organization. The model has been defined as a protobuf message because Protocol Buffers provide a highly efficient, compact, and language-neutral way to serialize structured data. This binary serialization format results in significantly smaller message sizes compared to text-based formats like JSON or YAML, which reduces network bandwidth usage and storage requirements</p>"},{"location":"model/#building-blocks","title":"Building Blocks","text":"<p>The infra.proto provides multiple building blocks to define the infrastructure. These blocks include:</p> <ul> <li>Inventory</li> <li>Device</li> <li>Components</li> <li>Links</li> <li>Device Instances</li> <li>Connections</li> </ul>"},{"location":"model/#devices","title":"Devices","text":"<pre><code>message Device {\n  optional string name = 1;\n  map&lt;string, Component&gt; components = 3;\n  map&lt;string, Link&gt; links = 4;\n  repeated string connections = 5;\n}\n</code></pre> <p>The Device message defines a device which is a part of the infrastructure. This contains a collection of components, links between the components and the connections. The main fields are: * name: An optional field allowing users to define the name of the device * components: A dictionary which stores the component message with the key as the component name. This message is defined in the later section * links: Another dictionary which stores the link message with the link name.  * connections: A list of connections that describe how components are connected to each other in a single device. Each element of this list is a string that describe the component connection and is described as:     <pre><code>source_component_name \".\" source_component_index \".\" link_name \".\" destination_component_name \".\" destination_component_index \n</code></pre>     example:     <pre><code>nic.0.pcie.cpu.0\nnpu.0.pcie.nvswitch.0\nasic.0.mii.nic.0\n</code></pre>     The source_component_name and destination_component_name is the name field present in the component message. This name also corresponds to the key of the components dictionary field which is a part of the device message. Each component message holds a count field which defines the number of components present in the device. These fields are defined later in the components section.</p>"},{"location":"model/#components","title":"Components","text":"<pre><code>message Component {\n  optional string name = 1;\n  optional uint32 count = 2;\n  oneof type {\n    CustomComponent custom = 10;\n    Cpu cpu = 11;\n    Npu npu = 12;\n    Nic nic = 13;\n    Switch switch = 14;\n  }\n}\n</code></pre> <p>The component message defines three major fields: * name: An optional field which gives the name of the component. The name is also provided as a key in the components dictionary field type of device message. * count: The count defines the total components present. Lets assume we have a nic component with a count of 8. This would create 8 instances of the nic component whose properies would remain the same with a zero based indexing. This is analogous to the concept of classes and objects where the component message acts as the blueprint and count indicates the number of objects created.  * type: The component datamodel allows to describe component of a certain type. The type can be:     * CPU     * NPU     * NIC     * Switch     * Custom</p> <pre><code>Each of these types are defined as another message. The section below describes the message format of component type.\n</code></pre>"},{"location":"model/#cpu-component","title":"CPU Component","text":"<p><pre><code>message Cpu {\n  MemoryType memory = 1;\n}\n</code></pre> This message defines the CPU type component. This allows the user to assign a certain memory type to the CPU. The MemoryType is covered in the later section.</p>"},{"location":"model/#npu-component","title":"NPU Component","text":"<pre><code>message Npu {\n  MemoryType memory = 1;\n}\n</code></pre> <p>This message defines the NPU type component. This allows the user to assign a certain memory type to the NPU. The MemoryType is covered in the later section.</p>"},{"location":"model/#custom-component","title":"Custom Component","text":"<pre><code>message CustomComponent {\n  MemoryType memory = 1;\n}\n</code></pre> <p>This message defines the CustomComponent type component. This allows the user to assign a certain memory type to the Custom Component. The MemoryType is covered in the later section.</p>"},{"location":"model/#memory-type","title":"Memory Type","text":"<p><pre><code>enum MemoryType {\n  MEM_UNSPECIFIED = 0;\n\n  // random access memory\n  MEM_RAM = 1;\n\n  // high bandwidth memory interface for 3D stacked sync dynamic random-access memory\n  MEM_HBM = 2;\n\n  // memory that uses compute express link interconnect to the cpu\n  MEM_CXL = 3;\n}\n</code></pre> The user can set either of the memory type to the CPU, NPU or CustomComponent Type. The memory could be either: * Unspecified * Random Access Memory * High Bandwidth Memory Interface * Compute Express Link</p> <p>The enum can be extended to add more memory types which can be used by custom component</p>"},{"location":"model/#nic-component","title":"NIC Component","text":"<pre><code>message Nic {\n  oneof type {\n    Ethernet ethernet = 10;\n    Infiniband infinband = 11;\n  }\n}\n\nmessage Infiniband {\n}\n\nmessage Ethernet {\n}\n</code></pre> <p>This describes the NIC Component. Each nic component can be of the following type: * Ethernet * Infiniband These types are defined as a message. </p>"},{"location":"model/#switch-component","title":"Switch Component","text":"<pre><code>message Switch {\n  oneof type {\n    Pcie pcie = 1;\n    NvLink nvswitch = 2;\n    Custom custom = 3;\n  }\n}\n\nmessage Pcie {\n}\n\nmessage NvLink {\n}\n\nmessage Custom {\n}\n</code></pre> <p>This section defines the Switch Component type. The switch component can be either of the following: * pcie * nvlink * custom</p> <p>These types are defined as a message. </p>"},{"location":"model/#link","title":"Link","text":"<pre><code>message Link {\n  optional string name = 1;\n  optional string description = 2;\n  Bandwidth bandwidth = 10;\n}\n\nmessage Bandwidth {\n  oneof type {\n    uint32 gbps = 1;\n    uint32 gBs = 2;\n    uint32 gts = 3;\n  }\n}\n</code></pre> <p>The Link message allows to define a \"link\" between the device as well as components. This model has three fields: * name * description * bandwidth</p> <p>The Bandwidth is defined as a message and allows to define the link bandwidth as: * gbps: gigabits per second * gBs: gigabytes per second * gts: giga transfers per second</p> <p>These take an unsigned integer value. The Links use the Bandwidth message model to define the link speed. </p>"},{"location":"model/#inventory","title":"Inventory","text":"<pre><code>message Inventory {\n  map&lt;string, Device&gt; devices = 1;\n  map&lt;string, Link&gt; links = 2;\n}\n</code></pre> <p>Inventory is a collection of all unique types of Devices and Links in the infrastructure. This has two major fields: * devices: </p> <pre><code>A collection of all unique types of devices in the infrastructure. The uniqueness is determined by the Device.name field.\n</code></pre> <ul> <li> <p>links:</p> <p>A collection of all unique types of links in the infrastructure. These links can be reused multiple times when creating connections between devices. The key is the Link.name which is used to guard against duplicates.</p> </li> </ul>"},{"location":"model/#device-instances","title":"Device Instances","text":"<pre><code>message DeviceInstances {\n  optional string name = 1;\n  optional string device = 2;\n  optional uint32 count = 3;\n}\n</code></pre> <p>The Device Instances message is used to instantiate the Device in the infrastructure. This message contains three fields: * name: the name of the device instance. This is used to categorize the device. For example: a switch defined in the inventory - devices message can be used as a Rack Switch, POD Switch or a Spine Switch. The name allows to create/provide a unique name to a set of devices.  * device: The name of the actual device that exist in the inventory - devices  field. This links the device which we want to use. * count: The number of instances of device in the infrastructure under this name. This should always be &gt;= 1. This also indiates the number of instances we need for a specific device under a certain name. This is again analogous to component modelling but done on a device level. The indexing starts at 0 and provides a unique identifier to create a device instance.</p>"},{"location":"model/#infrastructure","title":"Infrastructure","text":"<pre><code>message Infrastructure {\n  Inventory inventory = 1;\n  map&lt;string, DeviceInstances&gt; device_instances = 2;\n  repeated string connections = 3;\n}\n</code></pre> <p>The Infrastructure message establishes an inventory of devices and links, instances of the inventory, connectivity between those instances and any custom user information about devices, components, links and instances.</p> <p>This holds the inventory which contains the devices, links; the device_instances map that hold all the devices instantiated and a list of connections. The connection format is defined as a string of the following elements separated by a \".\"</p> <pre><code>source_device_instance_name\nsource_device_index \nsource_device_component_name\nsource_device_component_index\nlink_name\ndestination_device_instance_name\ndestination_device_index\ndestination_device_component_name\ndestination_device_component_index\n</code></pre> <p>This utilizes the device instances naming convention with the count which internally links to the  device message that defines the component, its name and the count and connects two different device instances with the link name that is defined in the inventory. </p>"},{"location":"model/#building-infrastructure","title":"Building Infrastructure","text":"<p>The model allows us to define devices, its internal components, as nodes and links as edges and creates connection as a link between the nodes thereby allowing to create a graph based representation. A step by step guide to create infrastructure is defined in Building A Cluster.</p>"},{"location":"schema/","title":"Schema","text":""},{"location":"schema/#introducing-the-infragraph-infrastructure-graph-schema","title":"Introducing the InfraGraph (INFRAstructure GRAPH) schema","text":"<p>A graph is a natural fit to describe a system of systems in a clear, intuitive, and mathematically precise manner.</p> <p></p> <ul> <li>Node or vertex represents an entity like a component, device, user, router, etc</li> <li>Edge represents a relationship between nodes</li> <li>Properties store additional information about nodes or edges</li> </ul>"},{"location":"schema/#principles","title":"Principles","text":"<p>InfraGraph is a <code>collection of APIs and Models</code> used to describe AI/HPC infrastructure based on the following core principles:</p> <ul> <li>infrastructure can be described using graph concepts such as vertexes, edges and properties<ul> <li>vertexes can be <code>component</code> or device <code>instances</code></li> <li>an edge contained by a device subgraph is 2 component instances separated by a link<ul> <li>e.g., <code>npu.0</code>.<code>pcie</code>.<code>nic.0</code></li> </ul> </li> <li>an edge contained by the infrastructure is 2 device connections separated by a link where a device connection is the device <code>instance</code> name and <code>index</code> and external <code>component</code> name and <code>index</code><ul> <li>e.g., <code>server.0</code>.<code>nic.0</code>.<code>eth</code>.<code>leafsw.0</code>.<code>port.0</code></li> </ul> </li> <li>a path is a collection of infrastructure and device connections between a single source and destination</li> <li>properties are fields with in the device and component objects</li> </ul> </li> <li>devices are composable using connections</li> <li>connections dictate the depth of the graph</li> <li>infrastructure and device connections dictate the shape of the graph</li> <li>infrastructure needs to be scalable without duplicating content</li> </ul>"},{"location":"schema/#openapiart","title":"OpenapiArt","text":"<p>This repository makes use of OpenAPIArt to do the following:</p> <ul> <li>create declarative intent based Models and APIs</li> <li>auto-generate the following artifacts:<ul> <li>openapi schema</li> <li>protobuf schema</li> <li>Redocly documentation of APIs and Models</li> <li><code>Python/Go SDKs</code> that allow for creating <code>fluent</code> client/server code over <code>REST/Protobuf</code> transports</li> </ul> </li> </ul>"},{"location":"unused/","title":"Unused","text":""},{"location":"unused/#features","title":"Features","text":"<p>Cluster Infrastructure as a graph is an actively developed specification, with contributions from real use cases. The model defines the following components to define a infrastructure:</p> <ul> <li>Device definitions with ability to model its internals as a graph</li> <li>Device Components allowing users to define the device internal components like:<ul> <li>nic</li> <li>ports</li> <li>npus</li> </ul> </li> <li>Links definition for:<ul> <li>components interconnect</li> <li>device interconnect</li> <li>Defining the bandwidth of the links</li> </ul> </li> <li>Connections between:<ul> <li>internal components of a device</li> <li>one device to another</li> </ul> </li> </ul> <p>Explore an in-depth explanation of the topology model, covering its structure, essential components, and how it supports efficient design and analysis. This resource provides valuable insights into the principles behind topology and how to apply them effectively.</p>"},{"location":"unused/#annotation","title":"Annotation","text":"<p>This section provides a comprehensive guide on how a user can annotate various parts of infrastructre and add more details like DeviceType, Rank Identifier and so on. It covers the model description with examples for binding physical attributes with the logical infrastructure definition.</p>"},{"location":"unused/#getting-started-with-topology-creation","title":"Getting Started With Topology Creation","text":"<p>This walkthrough guide demonstrates how anyone can create a topology from scratch, highlighting key steps and best practices to build a solid foundation. It offers a clear, step-by-step approach that makes topology creation accessible to beginners and experts alike.</p>"},{"location":"unused/#community","title":"Community","text":"<p>Use our community resources to get help with Infrastructure As A Graph:</p> <ul> <li>Infrastructure As A Graph on Github</li> </ul>"},{"location":"unused/#infrastructure-connections","title":"Infrastructure Connections","text":"<ul> <li>Create Connection between Components using Links</li> <li> <p>Defining External Links: Here we define the external link type that connects two devices</p> </li> <li> <p>Building the infrastructure as graph</p> </li> <li>Instantiating devices: Use the device definition in the inventory as a template to create multiple devices for the infrastructure.</li> <li>Defining connections: Use the external link definition to create connections between device instances.</li> </ul> <p>Follow these steps to design a Scale Up and Out Infrastructure.</p>"},{"location":"unused/#creating-device-inventory","title":"Creating Device Inventory","text":"<p>Device inventory outlines the necessary devices for infrastructure, including components and links. It acts as a blueprint to create and connect instances, aiming to define once and reuse multiple times for optimal space complexity. For example, in a network with 100 switches (50 each of 2 types) connected by 100G ethernet links, the inventory will only specify the 2 switch types and the 100G ethernet link type.</p> <p>Note that the entire device does not need to be described in full detail. The level of device detail should be dictated by the needs of the application.</p> <p>To define a Device:</p> <ul> <li>use the <code>Component</code> message to define individual components (vertexes) that are present in a device</li> <li>use the <code>Component - count</code> field to scale up the number of components in the device</li> <li>use the <code>Link</code> message to define different link types within the device</li> <li>use the <code>Device</code> message to contain <code>Component</code> and <code>Link</code> messages</li> <li>use the <code>Device - connections</code> field to connect components (vertexes) to each other with an associated link to form an edge</li> <li>the format of a <code>connections</code> string is described in the infra.proto file</li> </ul> <p>Now we will be designing a 4 port generic switch as a part of device inventory.</p>"},{"location":"unused/#defining-2-port-scale-up-switch","title":"Defining 2 port scale up switch","text":"<p>Lets define a simple 2 port scale up switch. </p> <p>This switch is made of two front panel ports.</p> <p>User can define this switch with one major \"port\" components inside it. These components can be viewed as nodes in a graph.</p> YAML Definition <pre><code>inventory:\n  devices:\n    SCALE_UP_SWITCH:\n      name: SCALE_UP_SWITCH\n      components:\n        port:\n          count: 2\n          name: port\n          nic:\n            ethernet: {}\n      connections: []\n      links: {}\n</code></pre> <p></p> JSON Definition <pre><code>{\n  \"inventory\": {\n    \"devices\": {\n      \"SCALE_UP_SWITCH\": {\n        \"name\": \"SCALE_UP_SWITCH\",\n        \"components\": {\n            \"port\": {\n                \"name\": \"port\",\n                \"count\": 2,\n                \"nic\": {\n                    \"ethernet\": { }\n                }\n            }\n        },\n        \"links\": {\n        },\n        \"connections\": [\n        ]\n    }\n  }\n}\n</code></pre> <p></p> <p>We have specified a scale up switch with 2 port components. Now we can define a scale out switch with 4 port components.</p>"},{"location":"unused/#defining-4-port-scale-out-switch","title":"Defining 4 port scale out switch","text":"<p>Lets define a simple 2 port scale up switch. </p> <p>This switch is made of four front panel ports.</p> <p>User can define this switch with one major \"port\" components inside it. These components are analogous to a node in a graph.</p> YAML Definition <pre><code>inventory:\n  devices:\n    SCALE_OUT_SWITCH:\n      name: SCALE_OUT_SWITCH\n      components:\n        port:\n          count: 4\n          name: port\n          nic:\n            ethernet: {}\n      connections: []\n      links: {}\n</code></pre> <p></p> JSON Definition <pre><code>{\n    \"inventory\": {\n        \"devices\": {\n            \"SCALE_OUT_SWITCH\": {\n                \"name\": \"SCALE_OUT_SWITCH\",\n                \"components\": {\n                    \"port\": {\n                        \"name\": \"port\",\n                        \"count\": 4,\n                        \"nic\": {\n                            \"ethernet\": { }\n                        }\n                    }\n                },\n                \"links\": {\n                },\n                \"connections\": [\n                ]\n            },\n        }\n    }\n}\n</code></pre> <p></p>"},{"location":"unused/#design-host-with-4-nics-and-single-npu","title":"Design host with 4 nics and single npu","text":"<p>Let's design a host with 4 nics and a single npu</p> <p></p> <p>Our Host has two interconnected components: - 4 nics - 1 npu</p> <p>These components are connected to each other via a pcie connection. Therefore to connect two different components, we can use the following notation:</p> <p><code>&lt;source&gt;.&lt;link&gt;.&lt;destination&gt;</code></p> <p>The <code>&lt;source&gt;</code> contains the source component and its index. The <code>&lt;destination&gt;</code> specifies the destination component and its index. The link joins the source and the destination. Therefore, the connection would look something like this:</p> <pre><code>&lt;source&gt;.&lt;src_index&gt;.&lt;link&gt;.&lt;destination&gt;.&lt;dst_index&gt;\n</code></pre> <p>These components can be defined as node in a graph which are connected through an edge (pcie) link in this case. We need to define the links as well as connections with which the whole device definition is defined below:</p> YAML Definition <pre><code>inventory:\n  devices:\n    HOST:\n      name: HOST\n      components:\n        nic:\n          name: nic\n          count: 4\n          nic:\n            ethernet: {}\n        npu:\n          name: npu\n          count: 1\n          npu: {}\n      links:\n        pcie:\n          name: pcie\n      connections:\n      - npu.0.pcie.nic.0\n      - npu.0.pcie.nic.1\n      - npu.0.pcie.nic.2\n      - npu.0.pcie.nic.3\n</code></pre> <p></p> JSON Definition <pre><code>{\n    \"inventory\": {\n        \"devices\": {\n            \"HOST\": {\n                \"name\": \"HOST\",\n                \"components\": {\n                    \"npu\": {\n                        \"name\": \"npu\",\n                        \"count\": 1,\n                        \"npu\": { }\n                    },\n                    \"nic\": {\n                        \"name\": \"nic\",\n                        \"count\": 4,\n                        \"nic\": {\n                            \"ethernet\": { }\n                        }\n                    }\n                },\n                \"links\": {\n                    \"pcie\": {\n                        \"name\": \"pcie\"\n                    }\n                },\n                \"connections\": [\n                    \"npu.0.pcie.nic.0\",\n                    \"npu.0.pcie.nic.1\",\n                    \"npu.0.pcie.nic.2\",\n                    \"npu.0.pcie.nic.3\"\n                ]\n            }\n        }\n    }\n}\n</code></pre> <p></p>"},{"location":"unused/#defining-links","title":"Defining Links","text":"<p>The objective is to define an infrastructure build using the switch and hosts defined earlier. The goal is to build an infrastructure where one switch is directly connected to four hosts via 100G Ethernet.</p> <p></p> <p>We have defined a switch and a host in the inventory, but not the 100G links. Let's define a 100G ethernet link as follows:</p> YAML Definition <pre><code>inventory:\n  links:\n  eth:\n    name: eth\n    description: Ethernet link\n    bandwidth:\n      gbps: 100\n</code></pre> <p></p> JSON Definition <pre><code>{\n  \"inventory\": {\n    \"links\": {\n      \"eth\": {\n        \"name\": \"eth\",\n        \"description\": \"Ethernet link\",\n        \"bandwidth\": {\n          \"gbps\": 100\n        }\n      }\n    }\n  }\n}\n</code></pre> <p></p> <p>In this example, we have defined a link <code>name: eth</code> with a bandwidth of 100 gbps. Subsequently, four such links will be utilized to connect four devices to four switch ports, as illustrated in the above image.</p>"},{"location":"unused/#creating-device-instances","title":"Creating Device Instances","text":"<p>We can scale the infrastructure by using the <code>device instance</code> message. To create a fully connected topology, we instantiate the defined devices by giving a new <code>instance_name</code> to the device followed by a count. Therefore to create instances for host, scale up and scale out switch, we define the instance as following:</p> YAML Definition <pre><code>deviceInstances:\n  host:\n    count: 4\n    device: HOST\n    name: host\n  sosw:\n    count: 2\n    device: SCALE_OUT_SWITCH\n    name: sosw\n  susw:\n    count: 4\n    device: SCALE_UP_SWITCH\n    name: susw\n</code></pre> <p></p> JSON Definition <pre><code>{\n    \"deviceInstances\": {\n        \"host\": {\n            \"name\": \"host\",\n            \"device\": \"HOST\",\n            \"count\": 4\n        },\n        \"susw\": {\n            \"name\": \"susw\",\n            \"device\": \"SCALE_UP_SWITCH\",\n            \"count\": 4\n        },\n        \"sosw\": {\n            \"name\": \"sosw\",\n            \"device\": \"SCALE_OUT_SWITCH\",\n            \"count\": 2\n        }\n    }\n}\n</code></pre> <p></p> <p>The devices are defined under the <code>inventory - devices</code> section, serving as a blueprint or template. These devices need to be instantiated to create the entire infrastructure, similar to creating objects of a class. With the specified count, multiple copies of the devices are created starting from index 0.</p> <p>Next, these device instances need to be connected over 100G ethernet links as illustrated in the picture above.</p>"},{"location":"unused/#connecting-device-instances","title":"Connecting Device Instances","text":"<p>Connections between the devices are made by the components of the device and links defined. Therefore, to connect two devices together, we need to define the connection in the following format:</p> <pre><code>&lt;src_device&gt;.&lt;dev_index&gt;&lt;src_component&gt;&lt;comp_index&gt;.&lt;link&gt;.&lt;dst_device&gt;.&lt;dev_index&gt;&lt;dst_component&gt;&lt;comp_index&gt;\n</code></pre> <p>The <code>&lt;src_device&gt;.&lt;dev_index&gt;&lt;src_component&gt;&lt;comp_index&gt;</code> specifies the source device, its index, component, and the component's index. The same format applies to the destination. The link defines the connection between source and destination.</p> <p>A \".\" separator separates infrastructure elements. To connect a <code>host</code> with the <code>scale_up_switch</code>, we define the connection as:</p> YAML Definition <pre><code>connections:\n  - host.0.nic.0.eth.susw.0.port.0\n</code></pre> <p></p> JSON Definition <pre><code>{\n  \"connections\": [\"host.0.nic.0.eth.susw.0.port.0\"]\n}\n</code></pre> <p></p> <p>The host at index 0, via its nic component 0, is connected to port 0 of scale up switch or <code>susw</code> 0. The link between this source and destination has a bandwidth of eth. This describes the first link shown in the above picture.</p> <p>Creating the links:</p> YAML Definition <pre><code>connections:\n    - host.0.nic.0.eth.susw.0.port.0\n    - host.0.nic.1.eth.susw.1.port.0\n    - host.0.nic.2.eth.sosw.0.port.0\n    - host.0.nic.3.eth.sosw.1.port.0\n    - host.1.nic.0.eth.susw.0.port.1\n    - host.1.nic.1.eth.susw.1.port.1\n    - host.1.nic.2.eth.sosw.0.port.1\n    - host.1.nic.3.eth.sosw.1.port.1\n    - host.2.nic.0.eth.susw.2.port.0\n    - host.2.nic.1.eth.susw.3.port.0\n    - host.2.nic.2.eth.sosw.0.port.2\n    - host.2.nic.3.eth.sosw.1.port.2\n    - host.3.nic.0.eth.susw.2.port.1\n    - host.3.nic.1.eth.susw.3.port.1\n    - host.3.nic.2.eth.sosw.0.port.3\n    - host.3.nic.3.eth.sosw.1.port.3\n</code></pre> <p></p> JSON Definition <pre><code>{\n  \"connections\": [\n        \"host.0.nic.0.eth.susw.0.port.0\",\n        \"host.0.nic.1.eth.susw.1.port.0\",\n        \"host.0.nic.2.eth.sosw.0.port.0\",\n        \"host.0.nic.3.eth.sosw.1.port.0\",\n        \"host.1.nic.0.eth.susw.0.port.1\",\n        \"host.1.nic.1.eth.susw.1.port.1\",\n        \"host.1.nic.2.eth.sosw.0.port.1\",\n        \"host.1.nic.3.eth.sosw.1.port.1\",\n        \"host.2.nic.0.eth.susw.2.port.0\",\n        \"host.2.nic.1.eth.susw.3.port.0\",\n        \"host.2.nic.2.eth.sosw.0.port.2\",\n        \"host.2.nic.3.eth.sosw.1.port.2\",\n        \"host.3.nic.0.eth.susw.2.port.1\",\n        \"host.3.nic.1.eth.susw.3.port.1\",\n        \"host.3.nic.2.eth.sosw.0.port.3\",\n        \"host.3.nic.3.eth.sosw.1.port.3\"\n    ]\n}\n</code></pre> <p></p>"},{"location":"unused/#the-complete-example","title":"The Complete Example","text":"<p>After combining all the definitions, we can arrive at the final design:</p> YAML Definition <pre><code>inventory:\n  devices:\n    HOST:\n      name: HOST\n      components:\n        nic:\n          name: nic\n          count: 4\n          nic:\n            ethernet: {}\n        npu:\n          name: npu\n          count: 1\n          npu: {}\n      links:\n        pcie:\n          name: pcie\n      connections:\n      - npu.0.pcie.nic.0\n      - npu.0.pcie.nic.1\n      - npu.0.pcie.nic.2\n      - npu.0.pcie.nic.3\n    SCALE_OUT_SWITCH:\n      name: SCALE_OUT_SWITCH\n      components:\n        port:\n          name: port\n          count: 4\n          nic:\n            ethernet: {}\n      links: {}\n      connections: []\n    SCALE_UP_SWITCH:\n      name: SCALE_UP_SWITCH\n      components:\n        port:\n          name: port\n          count: 2\n          nic:\n            ethernet: {}\n      links: {}\n      connections: []\n  links:\n    eth:\n      name: eth\n      bandwidth:\n        gbps: 100\n      description: Ethernet link\ndeviceInstances:\n  host:\n    name: host\n    device: HOST\n    count: 4\n  sosw:\n    name: sosw\n    device: SCALE_OUT_SWITCH\n    count: 2\n  susw:\n    name: susw\n    device: SCALE_UP_SWITCH\n    count: 4\nconnections:\n- host.0.nic.0.eth.susw.0.port.0\n- host.0.nic.1.eth.susw.1.port.0\n- host.0.nic.2.eth.sosw.0.port.0\n- host.0.nic.3.eth.sosw.1.port.0\n- host.1.nic.0.eth.susw.0.port.1\n- host.1.nic.1.eth.susw.1.port.1\n- host.1.nic.2.eth.sosw.0.port.1\n- host.1.nic.3.eth.sosw.1.port.1\n- host.2.nic.0.eth.susw.2.port.0\n- host.2.nic.1.eth.susw.3.port.0\n- host.2.nic.2.eth.sosw.0.port.2\n- host.2.nic.3.eth.sosw.1.port.2\n- host.3.nic.0.eth.susw.2.port.1\n- host.3.nic.1.eth.susw.3.port.1\n- host.3.nic.2.eth.sosw.0.port.3\n- host.3.nic.3.eth.sosw.1.port.3\n</code></pre> <p></p> JSON Definition <pre><code>{\n    \"inventory\": {\n        \"devices\": {\n            \"SCALE_OUT_SWITCH\": {\n                \"name\": \"SCALE_OUT_SWITCH\",\n                \"components\": {\n                    \"port\": {\n                        \"name\": \"port\",\n                        \"count\": 4,\n                        \"nic\": {\n                            \"ethernet\": { }\n                        }\n                    }\n                },\n                \"links\": {\n                },\n                \"connections\": [\n                ]\n            },\n            \"SCALE_UP_SWITCH\": {\n                \"name\": \"SCALE_UP_SWITCH\",\n                \"components\": {\n                    \"port\": {\n                        \"name\": \"port\",\n                        \"count\": 2,\n                        \"nic\": {\n                            \"ethernet\": { }\n                        }\n                    }\n                },\n                \"links\": {\n                },\n                \"connections\": [\n                ]\n            },\n            \"HOST\": {\n                \"name\": \"HOST\",\n                \"components\": {\n                    \"npu\": {\n                        \"name\": \"npu\",\n                        \"count\": 1,\n                        \"npu\": { }\n                    },\n                    \"nic\": {\n                        \"name\": \"nic\",\n                        \"count\": 4,\n                        \"nic\": {\n                            \"ethernet\": { }\n                        }\n                    }\n                },\n                \"links\": {\n                    \"pcie\": {\n                        \"name\": \"pcie\"\n                    }\n                },\n                \"connections\": [\n                    \"npu.0.pcie.nic.0\",\n                    \"npu.1.pcie.nic.1\",\n                    \"npu.2.pcie.nic.2\",\n                    \"npu.3.pcie.nic.3\"\n                ]\n            }\n        },\n        \"links\": {\n            \"eth\": {\n                \"name\": \"eth\",\n                \"description\": \"Ethernet link\",\n                \"bandwidth\": {\n                    \"gbps\": 100\n                }\n            }\n        }\n    },\n    \"deviceInstances\": {\n        \"host\": {\n            \"name\": \"host\",\n            \"device\": \"HOST\",\n            \"count\": 4\n        },\n        \"susw\": {\n            \"name\": \"susw\",\n            \"device\": \"SCALE_UP_SWITCH\",\n            \"count\": 4\n        },\n        \"sosw\": {\n            \"name\": \"sosw\",\n            \"device\": \"SCALE_OUT_SWITCH\",\n            \"count\": 2\n        }\n    },\n    \"connections\": [\n        \"host.0.nic.0.eth.susw.0.port.0\",\n        \"host.0.nic.1.eth.susw.1.port.0\",\n        \"host.0.nic.2.eth.sosw.0.port.0\",\n        \"host.0.nic.3.eth.sosw.1.port.0\",\n        \"host.1.nic.0.eth.susw.0.port.1\",\n        \"host.1.nic.1.eth.susw.1.port.1\",\n        \"host.1.nic.2.eth.sosw.0.port.1\",\n        \"host.1.nic.3.eth.sosw.1.port.1\",\n        \"host.2.nic.0.eth.susw.2.port.0\",\n        \"host.2.nic.1.eth.susw.3.port.0\",\n        \"host.2.nic.2.eth.sosw.0.port.2\",\n        \"host.2.nic.3.eth.sosw.1.port.2\",\n        \"host.3.nic.0.eth.susw.2.port.1\",\n        \"host.3.nic.1.eth.susw.3.port.1\",\n        \"host.3.nic.2.eth.sosw.0.port.3\",\n        \"host.3.nic.3.eth.sosw.1.port.3\"\n    ]\n}\n</code></pre> <p></p>"}]}